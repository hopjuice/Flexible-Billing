{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.ticker as mtick\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "import re \n",
    "from re import search\n",
    "import pyodbc as pc\n",
    "pd.set_option('display.max_columns', None)\n",
    "import calendar\n",
    "from time import strptime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "today = date.today()\n",
    "todaysdate = datetime.now()\n",
    "currentMonth = datetime.now().month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up sql connection and importing data\n",
    "conn_bi = pc.connect('''Driver={SQL Server};\n",
    "                            Server=sqlbi;\n",
    "                            Database=csn_junk;\n",
    "                            Trusted_Connection=yes'''\n",
    "                         )\n",
    "\n",
    "#sourcedata\n",
    "\n",
    "shipmentlistsql = 'select * from csn_reporting_bi.dbo.tblflexiblebillingspolist'\n",
    "oceanratesql = 'select * from csn_reporting_bi.dbo.OceanRates'\n",
    "bafsql = 'select * from csn_reporting_bi.dbo.BR_Monthly_BAF_Rates'\n",
    "drayratesql = 'select * from csn_reporting_bi.dbo.DrayRates'\n",
    "currencyconversionsql = 'select * from csn_reporting_bi.dbo.BR_Currency_Conversion'\n",
    "alreadybilledsql = 'select * from csn_reporting_bi.dbo.BRChargesSpoLevel' \n",
    "\n",
    "\n",
    "#converting source data to df\n",
    "shipmentinput = pd.read_sql(shipmentlistsql, conn_bi)\n",
    "oceanrate = pd.read_sql(oceanratesql, conn_bi)\n",
    "drayrate = pd.read_sql(drayratesql, conn_bi)\n",
    "baf = pd.read_sql(bafsql, conn_bi)\n",
    "currencyconversion = pd.read_sql(currencyconversionsql, conn_bi)\n",
    "alreadygenerated = pd.read_sql(alreadybilledsql, conn_bi)\n",
    "\n",
    "#closing connection\n",
    "conn_bi.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combining baf & currency conversion tables with shipmentlist\n",
    "\n",
    "shipmentlist = shipmentinput\n",
    "\n",
    "shipmentlist['EffectiveGateIn'] = shipmentlist['EffectiveGateIn'].astype('datetime64')\n",
    "shipmentlist['MonthTxt'] = shipmentlist['EffectiveGateIn'].dt.month.apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "\n",
    "#add additional months here\n",
    "baf = baf.rename(columns={'october':'Oct', 'september':'Sep','November':'Nov','december':'Dec',\n",
    "                          'january':'Jan','february':'Feb','march':'Mar','april':'Apr','origin':'BafOrigin', 'destination':'BafDestination'})\n",
    "\n",
    "bafmelt = pd.melt(baf, id_vars=['SignedMonth', 'BafOrigin','BafDestination'], \n",
    "               var_name = 'MonthTxt', value_name='BafRate' ).dropna().reset_index(drop=True)\n",
    "\n",
    "### Need to merge on signed month as well, once this is in db\n",
    "shipmentlist = pd.merge(shipmentlist,bafmelt,how='left', on=['BafOrigin', 'BafDestination', 'MonthTxt', 'SignedMonth'])\n",
    "shipmentlist = pd.merge(shipmentlist,currencyconversion, on=['ShipmentID','ServiceLevel'],how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the destination country\n",
    "shipmentlist['country'] = shipmentlist['DestinationPort'].str[0:2]\n",
    "\n",
    "def definecountry(s):\n",
    "    if s['country'] == 'US':\n",
    "        return 'USA'\n",
    "    if s['country'] == 'CA':\n",
    "        return 'CAN'\n",
    "    if s['country'] == 'GB':\n",
    "        return 'GB'\n",
    "    else:\n",
    "        return 'DE'\n",
    "    \n",
    "shipmentlist['country'] = shipmentlist.apply(definecountry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing in Exceptions\n",
    "\n",
    "#Exceptions: Port Codes - fixing bad port Codes in source data\n",
    "origincodefix = {\n",
    "\n",
    "#Syntax: 'BadPortCode':'CorrectPortCode'\n",
    "    'CNSHA':'CNSHG',\n",
    "    'CNXMN':'CNXMG',\n",
    "    'CNSGH':'CNSHG',\n",
    "    'VNBHA':'VNSGN',\n",
    "    'VNDNA':'CNSHG',\n",
    "    'VNVUT':'VNSGN',\n",
    "    'VNBDU':'VNSGN',\n",
    "    'KHSCH':'KHKOS',\n",
    "    'CNNGB':'CNNBG',\n",
    "    'CNNKGP':'CNNJG',\n",
    "    'CNTAO':'CNQDG',\n",
    "    'VNQNT':'VNUIH',\n",
    "}\n",
    "\n",
    "destinationcodefix = {\n",
    "    'USORF':'USCVG',\n",
    "    'USNWK':'USNYC',\n",
    "    'USFWT':'USDAL',\n",
    "    'USLTX':'USDAL',\n",
    "    'USPER':'USLGB',\n",
    "    'DEHMY':'DEHAM',    \n",
    "}\n",
    "\n",
    "shipmentlist['OriginPort'] = shipmentlist['OriginPort'].map(origincodefix).fillna(shipmentlist['OriginPort'])\n",
    "shipmentlist['DestinationPort'] = shipmentlist['DestinationPort'].map(destinationcodefix).fillna(shipmentlist['DestinationPort'])\n",
    "\n",
    "#Exception: Kassel - All DE shipments are going to Hammersbach but cube shows they went to Kassel \n",
    "shipmentlist['whid'].replace(to_replace=33191, value=172055, inplace=True)\n",
    "\n",
    "#Exception: LLY Tech has a unique AAS rate into USHOU, for the rest of shipments however the portcode needs to be USDAL  \n",
    "shipmentlist['DestinationPort'] = np.where(((shipmentlist['DestinationPort'] == 'USHOU') & ((shipmentlist['SuID'] != 10909) \n",
    "                                    & (shipmentlist['ServiceLevel'] != 'OND'))),'USDAL',shipmentlist['DestinationPort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting data\n",
    "\n",
    "oceanrate['SuID'] = oceanrate['SuID'].astype('int')\n",
    "drayrate['SuID'] = drayrate['SuID'].astype('int')\n",
    "shipmentlist['ContainerSize'] =shipmentlist['ContainerSize'].astype('int')\n",
    "\n",
    "#converting dates\n",
    "dateconvert = ['ATD', 'GateOut', '1stReceipt']\n",
    "shipmentlist[dateconvert] = shipmentlist[dateconvert].astype('datetime64')\n",
    "\n",
    "#dropping extra effective + expiration dates\n",
    "try: \n",
    "    oceanrate = oceanrate.drop(columns = ['ScExpiredDate', 'ScEffectiveDate'])\n",
    "    drayrate = drayrate.drop(columns = ['ScExpiredDate', 'ScEffectiveDate','DestinationPort'])\n",
    "    \n",
    "except:\n",
    "    print('Already Removed')\n",
    "    \n",
    "drayrate = drayrate.drop_duplicates().reset_index(drop=True)\n",
    "drayrate = drayrate[(drayrate['DrayRate'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding ocean and dray rates to each shipment\n",
    "\n",
    "shipmentswocean = pd.merge(shipmentlist,oceanrate, \n",
    "                           on=('OceanContract', 'SuID', 'DestinationPort', 'OriginPort', 'ServiceLevel','ContainerSize'),\n",
    "                           how ='left')\n",
    "\n",
    "spostobill = pd.merge(shipmentswocean,drayrate[['DrayContract','SuID','whid', 'ServiceLevel', 'DrayRate','ContainerSize']],\n",
    "                     on=('DrayContract','SuID','whid','ServiceLevel','ContainerSize'), how ='left')  \n",
    "\n",
    "rates = ['OceanRate', 'DDOCRate', 'DrayRate', 'SecurityFee', 'DTHC', 'BafRate', 'PSS Rate']\n",
    "spostobill[rates] = spostobill[rates].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying rates + adding standard rates\n",
    "\n",
    "#Exception: standard dray rates\n",
    "spostobill['DrayRate'] = np.where((spostobill['country'] == 'GB') & (spostobill['ServiceLevel'] == 'ACN')\n",
    "                                  ,10.4,spostobill['DrayRate'])\n",
    "spostobill['DrayRate'] = np.where((spostobill['country'] == 'DE') & (spostobill['ServiceLevel'] == 'ACN')\n",
    "                                  ,10.9,spostobill['DrayRate'])\n",
    "spostobill['DrayRate'] = np.where((spostobill['country'] == 'CAN') & (spostobill['ServiceLevel'] == 'ACN')\n",
    "                                  ,8,spostobill['DrayRate'])\n",
    "spostobill['DrayRate'] = np.where((spostobill['whid'] == 33194)& (spostobill['ServiceLevel'] == 'NVO')\n",
    "                                  ,566,spostobill['DrayRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supplier exceptions\n",
    "\n",
    "#Exception: GFW\n",
    "gfwdrop = spostobill[(spostobill['SuID'] ==  13955) & (spostobill['ATD'].dt.month  !=  (currentMonth-1))] \n",
    "spostobill = spostobill.drop(gfwdrop.index, axis=0)\n",
    "\n",
    "#Exception: TGC \n",
    "spostobill['SuID'] = np.where(spostobill['SuID'] == 13758,65140,spostobill['SuID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#billing functions\n",
    "\n",
    "def pierpass(df): \n",
    "    if df['ServiceLevel'] == 'ACN' and df['DestinationPort'] == 'USLGB':\n",
    "        return df['CBM'] * 1.03\n",
    "    if df['ServiceLevel'] == 'ACN' and df['DestinationPort'] == 'USLAX':\n",
    "        return df['CBM'] * 1.03\n",
    "    if df['ServiceLevel'] == 'ACN' and df['DestinationPort'] == 'USOAK':\n",
    "        return df['CBM'] * .56\n",
    "    elif df['DestinationPort'] == 'USOAK': \n",
    "        return df['CBM'] * 36.4\n",
    "    elif df['DestinationPort'] == 'USLGB':\n",
    "        return df['CBM'] * 66.95\n",
    "    elif df['DestinationPort'] == 'USLAX':\n",
    "        return df['CBM'] * 66.95\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def caliport (df):\n",
    "    if df['DestinationPort'] in ['USLGB', 'USOAK']:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "    \n",
    "    \n",
    "def drayfuelbill (df):\n",
    "    if df['country'] == 'USA' and df['cali'] == 'yes':\n",
    "        return df['California Percent'] * df['draybasecharge']\n",
    "    if df['country'] == 'USA' and df['cali'] == 'no':\n",
    "        return df['US Percent'] * df['draybasecharge']\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def bunkerrate(df):\n",
    "    if df['ServiceLevel'] == 'DRA':\n",
    "        return 0\n",
    "    elif df['ServiceLevel'] == 'ACN':\n",
    "        return df['CBM'] / 65 * df['BafRate']\n",
    "    else:\n",
    "        return df['CBM'] * df['BafRate']\n",
    "\n",
    "    \n",
    "cranwhid = [13221, 13217, 156348]\n",
    "def cranfee(df): \n",
    "    if df['ServiceLevel'] == 'ACN' and df['whid'] in [13221, 13217, 156348]:\n",
    "        return df['CBM'] * .2615\n",
    "    elif df['whid'] in [13221, 13217, 156348]:\n",
    "        return 17\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating charges\n",
    "spostobill['cali'] = spostobill.apply(caliport, axis=1)\n",
    "\n",
    "#AC\n",
    "spostobill['cfscharge'] = np.where((spostobill['ServiceLevel'] == 'ACN'), spostobill['CBM']*10, 0) * spostobill['CFS Exchange Rate']\n",
    "\n",
    "#oceancharges\n",
    "spostobill['oceanbasecharge'] = spostobill['OceanRate'] * spostobill['CBM'] * spostobill['Ocean Exchange Rate']\n",
    "spostobill['bunker'] = spostobill.apply(bunkerrate, axis=1) * spostobill['Ocean Exchange Rate']\n",
    "spostobill['ddoccharge'] =  spostobill['DDOCRate'] * spostobill['Ocean Exchange Rate'] * spostobill['CBM']\n",
    "spostobill['psscharge'] = spostobill['CBM'] * spostobill['PSS Rate'] * spostobill['Ocean Exchange Rate']\n",
    "spostobill['pierpasscharge'] = np.where(spostobill['ServiceLevel'] != 'DRA',spostobill.apply(pierpass, axis=1),0) * spostobill['Ocean Exchange Rate']\n",
    "spostobill['Securitycharge'] =  np.where(spostobill['country'].isin(['DE','GB']),spostobill['SecurityFee'],0) * spostobill['Ocean Exchange Rate']\n",
    "spostobill['DTHCFee'] =  np.where(spostobill['country'].isin(['DE','GB']),spostobill['DTHC'],0) * spostobill['Ocean Exchange Rate']\n",
    "spostobill['CranFee'] = spostobill.apply(cranfee, axis=1)\n",
    "\n",
    "#draycharges\n",
    "spostobill['draybasecharge'] = spostobill['DrayRate'] * spostobill['CBM'] * spostobill['Dray Exchange Rate']\n",
    "spostobill['drayfuelcharge'] = np.where(spostobill['ServiceLevel'].isin(['ACN','NVO','OND', 'DRA','NOR']),\n",
    "                                        spostobill['draybasecharge']*spostobill['DFSCPercentage'],0) * spostobill['Dray Exchange Rate']\n",
    "#CargoProtect Charges\n",
    "cargoprotectrates = ['cfscharge', 'oceanbasecharge', 'ddoccharge'\n",
    "                     ,'bunker','psscharge', 'draybasecharge', 'drayfuelcharge','Securitycharge', 'DTHCFee']\n",
    "spostobill['InsuranceCharge'] = (spostobill[cargoprotectrates].sum(axis=1) + spostobill['Wholesale Value'])/100*spostobill['CargoProtectRate']\n",
    "\n",
    "#adding all charges up\n",
    "passthroughs = ['pierpasscharge', 'CranFee']\n",
    "spostobill['TotalAmount'] = spostobill[cargoprotectrates].sum(axis=1) + spostobill['InsuranceCharge'] + spostobill[passthroughs].sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Formatting and saving to T-Drive  Q/A file \n",
    "\n",
    "\n",
    "#narrowing columns\n",
    "allcharges = spostobill[['ShipmentID','OceanContract','DrayContract','ACISpoID', 'SuID','Supplier Currency', 'ServiceLevel',\n",
    "                         'SignedMonth', 'CBM', 'ContainerNumber', 'EffectiveGateIn','GateIn', 'ATD','1stReceipt','GateOut',\n",
    "                         'OriginPort', 'DestinationPort','DestinationWarehouse','country','whid', 'wmswhid','cfscharge', \n",
    "                         'oceanbasecharge', 'ddoccharge','bunker','pierpasscharge', 'psscharge','draybasecharge', \n",
    "                         'drayfuelcharge','Securitycharge','DTHCFee', 'InsuranceCharge', 'CranFee','TotalAmount','CFS Exchange Rate', \n",
    "                         'Ocean Exchange Rate','Dray Exchange Rate']]\n",
    "\n",
    "\n",
    "#fixing service levels desigination and breaking out OaaS suppliers\n",
    "allcharges['ServiceLevel'] = np.where(allcharges['ServiceLevel'] == 'NOR','NVO',allcharges['ServiceLevel'])\n",
    "allcharges['ServiceLevel'] = np.where(((allcharges['SuID'].isin([36651, 12128, 405])) \n",
    "                                       & (allcharges['ServiceLevel'] == 'OND')),'OaaS',allcharges['ServiceLevel'])\n",
    "\n",
    "\n",
    "#formatting\n",
    "finalrates = cargoprotectrates + ['InsuranceCharge', 'TotalAmount'] + passthroughs\n",
    "allcharges[finalrates] = allcharges[finalrates].round(2)\n",
    "\n",
    "#comma in Oaas warehouse names messed up CSV\n",
    "allcharges['DestinationWarehouse'] = allcharges['DestinationWarehouse'].str.replace(',','')\n",
    "\n",
    "#removing spos that are fully billed\n",
    "chargestoaddtosql = pd.merge(allcharges,alreadygenerated[['Fully Billed', 'ShipmentID', 'Some Charges']],\n",
    "                             on = 'ShipmentID', how='left') \n",
    "shipmentstobill = chargestoaddtosql[(chargestoaddtosql['Fully Billed'] == 'No')]\n",
    "\n",
    "#dropping any duplicates\n",
    "allcharges = allcharges.drop_duplicates().reset_index(drop=True)\n",
    "shipmentstobill = shipmentstobill.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \n",
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Begin converting file from output Q/A file to bulk upload file \n",
    "\n",
    "#narrowing shipments based on charge generation trigger & eliminating null GateIns except for DRA Only Shipments\n",
    "billingtrigger = today#.replace(day=1) - timedelta(days=5)\n",
    "notdra = shipmentstobill[(shipmentstobill['ATD'] < billingtrigger) & (shipmentstobill['ServiceLevel'] != 'DRA')] \n",
    "\n",
    "notdra = notdra[(notdra['GateIn'].notnull())]\n",
    "dra = shipmentstobill[(shipmentstobill['GateOut'] < billingtrigger) & (shipmentstobill['ServiceLevel'] == 'DRA')]\n",
    "\n",
    "#bringing charge files back together\n",
    "blt1 = pd.concat([dra,notdra]) \n",
    "\n",
    "#Consolidating values, i.e (ChargeDate, WHID, Contract #) \n",
    "    #chargedate and contract number for DRA only are different values than other servicelevels\n",
    "    #OND shipments the whid is an NCT value, for other servicelevels we use wms whid\n",
    "    \n",
    "blt1['ChargeDate'] = np.where(blt1['ServiceLevel'] == 'DRA',blt1['GateOut'], blt1['ATD'])\n",
    "blt1['WarehouseID'] = np.where(blt1['ServiceLevel'].isin(['OND','OaaS']),blt1['whid'],blt1['wmswhid'])\n",
    "blt1['Contract'] = np.where(blt1['ServiceLevel']=='DRA',blt1['DrayContract'],blt1['OceanContract'])\n",
    "\n",
    "#removing excess columns in big file\n",
    "bltcolumns = ['SuID', 'ACISpoID', 'ChargeDate', 'WarehouseID', 'ShipmentID', 'ServiceLevel','ContainerNumber', 'country','CBM',\n",
    "              'Supplier Currency','Contract','GateIn','CFS Exchange Rate', 'Ocean Exchange Rate',\n",
    "             'Dray Exchange Rate','Some Charges']\n",
    "\n",
    "blt1 = blt1[bltcolumns]\n",
    "    \n",
    "#Pivoting out charges; going from spo level granularity to charge type level granularity\n",
    "blt = shipmentstobill[['ShipmentID','cfscharge','oceanbasecharge','ddoccharge','bunker', 'draybasecharge', 'drayfuelcharge', \n",
    "                       'psscharge', 'pierpasscharge','CranFee', 'Securitycharge', 'DTHCFee']] \n",
    "\n",
    "blt = pd.melt(blt, id_vars=['ShipmentID'],var_name = 'chargetype', value_name='UnitPrice').dropna().reset_index(drop=True)\n",
    "\n",
    "#dropping lines w/o a charge\n",
    "blt = blt[(blt['UnitPrice'] != 0)]\n",
    "\n",
    "#merging shipment details to charges\n",
    "blt1 = pd.merge(blt1,blt, on= 'ShipmentID', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "blt1['ChargeNote']  = blt1['chargetype'].map(NOTE_ROW_HEADER) \n",
    "\n",
    "blt1['ChargeNote'] = np.where(blt1['ContainerNumber'].isnull(),blt1['ChargeNote'],\n",
    "                             blt1['ChargeNote'] + 'ContainerNumber: ' + blt1['ContainerNumber'])\n",
    "blt1['ChargeNote'] = np.where(blt1['ServiceLevel'] == 'ACN',blt1['ChargeNote'] +', ACI: ' + blt1['ACISpoID'],\n",
    "                              blt1['ChargeNote'])\n",
    "blt1['ChargeNote'] = blt1['ChargeNote'] + ', Contract: ' + blt1['Contract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing External Note\n",
    "\n",
    "cfscharges = ['cfscharge']\n",
    "oceancharges = ['oceanbasecharge','ddoccharge','bunker','psscharge', 'pierpasscharge','Securitycharge', 'DTHCFee']\n",
    "draycharges = ['draybasecharge', 'drayfuelcharge','CranFee']\n",
    "\n",
    "blt1['ExchangeRate'] = np.where(blt1['chargetype'].isin(cfscharges),blt1['CFS Exchange Rate'],0)\n",
    "blt1['ExchangeRate'] = np.where(blt1['chargetype'].isin(oceancharges),blt1['Ocean Exchange Rate'],blt1['ExchangeRate'])\n",
    "blt1['ExchangeRate'] = np.where(blt1['chargetype'].isin(draycharges),blt1['Dray Exchange Rate'],blt1['ExchangeRate'])\n",
    "\n",
    "blt1['OriginalChargeAmount'] = (blt1['UnitPrice'] / blt1['ExchangeRate']).round(1)\n",
    "\n",
    "#Charge Dict\n",
    "NOTE_ROW_HEADER = {\n",
    "    'cfscharge': 'Asia Consolidation - CFS Charge, ',\n",
    "    'oceanbasecharge': 'Ocean Freight - Base, ',\n",
    "    'bunker':'Ocean Freight - Bunker Adjustment, ',\n",
    "    'psscharge': 'Ocean Freigt - Peak Season Surchage, ',\n",
    "    'ddoccharge': 'Ocean Freight - DDOC, ',\n",
    "    'Securitycharge': 'Ocean Freight - Security Fee, ',\n",
    "    'DTHCFee': 'Ocean Freight - DTHC, ',\n",
    "    'CranFee': 'Drayage - Cranbury Gate Fee, ',\n",
    "    'pierpasscharge': 'Drayage - Pier Pass Fee, ',\n",
    "    'draybasecharge': 'Drayage - Base, ',\n",
    "    'drayfuelcharge': 'Drayage - Fuel, ',\n",
    "    'InsuranceCharge': 'CargoProtect Insurance '    \n",
    "    \n",
    "}\n",
    "\n",
    "#externalnote functions\n",
    "def generate_note(s):\n",
    "    try:\n",
    "        if s['ServiceLevel'] == 'ACN':\n",
    "            return NOTE_ROW_HEADER[s['chargetype']] + generate_not_detailsAC(s)\n",
    "        if s['ServiceLevel'] != 'ACN':\n",
    "            return NOTE_ROW_HEADER[s['chargetype']] + generate_not_details(s)\n",
    "    except KeyError:\n",
    "        return f\"Invalid Charge Type {s['chargetype']}\"\n",
    "    \n",
    "def generate_not_detailsAC(s):\n",
    "    return f\"ContainerNumber: {s['ContainerNumber']}, ACI: {s['ACISpoID']}, Contract: {s['Contract']}\"\n",
    "\n",
    "def generate_not_details(s):\n",
    "    return f\"ContainerNumber: {s['ContainerNumber']}, Contract: {s['Contract']}\"\n",
    "\n",
    "#writing ExternalNote W/O Original Rate    \n",
    "blt1['ExternalNote'] = blt1.apply(generate_note, axis = 1)\n",
    "\n",
    "def currencyconversionnote(s):\n",
    "    if s['ExchangeRate'] != 1:\n",
    "        return s['ExternalNote'] + ', Converted From: ' + str(s['OriginalChargeAmount'])\n",
    "    else:\n",
    "        return s['ExternalNote']\n",
    "    \n",
    "#Adding OriginalRate   \n",
    "blt1['ExternalNote'] = blt1.apply(currencyconversionnote, axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final BLT formatting\n",
    "\n",
    "blt2 = blt1\n",
    "\n",
    "#addding random columns for blt\n",
    "blt2['QTY'] = 1\n",
    "bltextracol = ['FulfillmentPoNumber', 'SprID','StartDate','EndDate','VatType']\n",
    "blt2 = blt2.reindex(columns=blt2.columns.tolist() + bltextracol) \n",
    "blt2[bltextracol] = ''\n",
    "\n",
    "#trimmingcolumns -- keeping chargetype, containernumber, somecharges, and cbm for data verifcation purposes \n",
    "blt5 = blt2[['SuID', 'ChargeDate', 'QTY', 'UnitPrice','UnitPrice', 'WarehouseID', 'ShipmentID', 'FulfillmentPoNumber', 'SprID',#\n",
    "             'StartDate','EndDate','ExternalNote','VatType','ServiceLevel','chargetype', 'ContainerNumber', 'country',\n",
    "             'CBM','Supplier Currency','Some Charges']]\n",
    "\n",
    "#renaming columns for blt\n",
    "finalbltcolumns = ['SupplierID', 'ChargeDate', 'QTY', 'UnitPrice', 'TotalAmount', 'WarehouseID','SpoID', 'FulfillmentPoNumber',\n",
    "             'SprID', 'StartDate', 'EndDate', 'ExternalNote','VatType','ServiceLevel','chargetype','ContainerNumber',\n",
    "              'country', 'CBM','Supplier Currency','Some Charges']\n",
    "\n",
    "blt5.columns = [finalbltcolumns]\n",
    "\n",
    "#formatting dtypes for blt \n",
    "bltnumbers = ['SupplierID','WarehouseID']\n",
    "blt5[bltnumbers] = blt5[bltnumbers].astype(int).round(2)\n",
    "\n",
    "#dropping any dupes\n",
    "finalblt = blt5.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#outputing to T-Drive\n",
    "path = (r'T:\\SalesAndOps\\Logistics\\International Supply Chain\\Billing and Reconciliation\\Flexible Billing\\Charge Output')\n",
    "\n",
    "output_file1 = os.path.join(path,str(today)+' - AllCharges.csv')\n",
    "output_file2 = os.path.join(path,str(today)+' - ShipmentsToBill.csv')\n",
    "output_file3 = os.path.join(path,str(today)+' - Bulk Upload.csv')\n",
    "\n",
    "finalblt.to_csv(output_file3)\n",
    "allcharges.to_csv(output_file1)\n",
    "shipmentstobill.to_csv(output_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rl409b\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and 'the values will not compare equal to the\n",
      "'datetime.date'. To retain the current behavior, convert the\n",
      "'datetime.date' to a datetime with 'pd.Timestamp'.\n"
     ]
    }
   ],
   "source": [
    "#supplier specific logic below \n",
    "\n",
    "#filltering charges to only those being sent to a supplier\n",
    "firstbiz = pd.date_range('9/1/2020', '12/1/2022', freq='BMS')\n",
    "\n",
    "## dictionary with suppliers in program\n",
    "\n",
    "SUPPLIER_PREFERENCE_DICT = {\n",
    "    #milestone options are 1strecipt or atd, gate-in\n",
    "    #cadence options are not null or monthly\n",
    "    \n",
    "    12128: {\n",
    "            'milestone': '1streceipt',\n",
    "            'cadence': 'notnull',\n",
    "        },\n",
    "    1837: {\n",
    "        'milestone': 'ATD',\n",
    "        'cadence': 'monthly',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "##adding values from dictionary\n",
    "\n",
    "def milestonedate (df):\n",
    "    try: \n",
    "        supplier_info = SUPPLIER_PREFERENCE_DICT[df['SuID']] \n",
    "        milestone_date = df[supplier_info['milestone']] \n",
    "        return milestone_date\n",
    "    except: ''\n",
    "        \n",
    "def cadence (df):\n",
    "    try: \n",
    "        cadence = SUPPLIER_PREFERENCE_DICT[df['SuID']]['cadence'] \n",
    "        return cadence\n",
    "    except: ''\n",
    "\n",
    "allcharges['milestonedate'] = allcharges.apply(milestonedate, axis =1)\n",
    "allcharges['cadence'] = allcharges.apply(cadence, axis =1)\n",
    "\n",
    "#filtering df to only shipments with requiste milestone\n",
    "supplieroutput = allcharges[(allcharges['milestonedate'].notnull())].reset_index(drop=True)\n",
    "\n",
    "#spliting df into monthly, not null \n",
    "monthlycharges = supplieroutput[(supplieroutput['cadence']=='monthly')]\n",
    "notnullcharges = supplieroutput[(supplieroutput['cadence']=='notnull')]\n",
    "nntodaycharges = supplieroutput[(supplieroutput['milestonedate'] == today)]\n",
    "\n",
    "#monthly workflow\n",
    "month = today.month - 1 \n",
    "month_mask = supplieroutput['milestonedate'].map(lambda x: x.month) == month ##only filtering on month\n",
    "month_output = supplieroutput[month_mask]\n",
    "monthlysuids = month_output['SuID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtoday =  '2020-9-01'\n",
    "#outputing to shared drive\n",
    "DataFrameDict = {elem : pd.DataFrame for elem in monthlysuids}\n",
    "if testtoday in firstbiz:\n",
    "    for key in DataFrameDict:\n",
    "        month_output[:][month_output.SuID == key].to_csv(os.path.join(path,str(today) + ', SUID-' + str(key) +'.csv'))\n",
    "\n",
    "nn_suids = notnullcharges['SuID'].unique()\n",
    "nn_DataFrameDict = {elem : pd.DataFrame for elem in nn_suids}\n",
    "for key in nn_DataFrameDict:\n",
    "   nntodaycharges[:][nntodaycharges.suid == key].to_csv((os.path.join(path,str(today) + ', SUID-' + str(key) +'.csv')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
